{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Simple Linear Network and the Delta Rule\n",
    "##\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as R\n",
    "\n",
    "# supress unnecessary warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create input training patterns and training teacher output\n",
    "\n",
    "Np  = # training patterns<br>\n",
    "nin = # input nodes\n",
    "\n",
    "input pattern array (i) should have dimensions Np x nin\n",
    "\n",
    "With Np=10 and nin=1, note that the original shape of i is (10,) instead of (10,1) - we need to reshape i to explicitly have dimensions (10,1)\n",
    "\n",
    "similarity, the training teacher output array (t) should have dimensions Np x nout - we need to reshape t to explicitly have dimensions (10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input patterns\n",
    "i = np.array([0.12, 0.16, 0.21, 0.25, 0.32, 0.39, 0.45, 0.52, 0.59, 0.68]);\n",
    "nin = 1\n",
    "print('original shape of i : {}'.format(i.shape))\n",
    "\n",
    "# force i to have shape to be Np x nin\n",
    "i = i.reshape((i.shape[0],nin))\n",
    "print('re-shaped i : {}'.format(i.shape))\n",
    "\n",
    "# alternatively, instead of explicitly re-shaping the array, could have defined i this way\n",
    "# i = np.array([[0.12], [0.16], [0.21], [0.25], [0.32], [0.39], [0.45], [0.52], [0.59], [0.68]]);\n",
    "\n",
    "# number of patterns\n",
    "Np = i.shape[0]\n",
    "\n",
    "# teacher outputs\n",
    "t = np.array([0.34, 0.54, 0.72, 0.91, 1.21, 1.35, 1.58, 1.69, 1.80, 2.01]);\n",
    "nout = 1\n",
    "# force t to have shape to be Np x nout\n",
    "t = t.reshape((t.shape[0],nout))\n",
    "\n",
    "# test patterns\n",
    "test = np.linspace(0, .7, 20)\n",
    "# force test to have shape to be Ntest x nout\n",
    "test = test.reshape((test.shape[0],nin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### here we implement delta rule learning by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "## delta rule learning by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whereas using Keras (and other toolkits) we do not need to explicitly create the input (with value 1) to the bias weight (Keras and those toolkits take care of that automatically), here we need to explicitly add those inputs\n",
    "\n",
    "so instead of having Np x nin array, we will have an NP x (nin+1) array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing by hand, we want to add the explicit input (with value 1) via the bias weight\n",
    "idelta = np.concatenate((i, np.ones((i.shape[0],1))), axis=1)\n",
    "nindelta = idelta.shape[1]\n",
    "\n",
    "print('original input i')\n",
    "print(i)\n",
    "print()\n",
    "print('input idelta (with column of 1s concatenated)')\n",
    "print(idelta)\n",
    "\n",
    "# need to do the same for the test inputs\n",
    "testdelta = np.concatenate((test, np.ones((test.shape[0],1))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note here that we initialize the weight matrix (Wdelta) to small random numbers\n",
    "\n",
    "while this is not critical for simple delta rule learning, it will be for training most complex networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "LR = .01\n",
    "\n",
    "# initialize weight matrix to small random values\n",
    "Wdelta = .10*R.rand(nindelta,nout)-.05;\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you turn verbose to True, you can see how the error (SSE) decreases over training\n",
    "\n",
    "note that this implements incremental learning (aka stochastic gradient descent) - weights are updated after every training pattern rather than once per epoch (or in batches)\n",
    "\n",
    "and note that I have given code that calculates the output given the input using both matrix operations and using nested for loops (they give the same answer, but the first method is a lot faster to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear activation function\n",
    "def linear(net):\n",
    "    return net\n",
    "\n",
    "# initialize err array\n",
    "err = np.zeros((epochs))\n",
    "\n",
    "# if verbose, print progress\n",
    "verbose = False\n",
    "\n",
    "# loop through epochs\n",
    "for N in range(epochs):\n",
    "        \n",
    "    # initalize output\n",
    "    outdelta = np.zeros((t.shape[0],1))\n",
    "    \n",
    "    # shuffle order of patterns (M for remapping) - necessary for sgd\n",
    "    M = R.permutation(Np)\n",
    "    \n",
    "    # incremental learning / stochastic gradient descent\n",
    "    for p in range(Np):\n",
    "\n",
    "        # calculate output given input p (using matrix operation in one line of code)\n",
    "        outdelta[[M[p]],:] = linear(np.matmul(idelta[[M[p]],:], Wdelta))\n",
    "        \n",
    "        # now calculate output given input p long-hand (using a for loop instead)\n",
    "        for J in range(nout):\n",
    "            net = 0.\n",
    "            for I in range(nindelta):\n",
    "                net += idelta[M[p],I] * Wdelta[I,J]\n",
    "            outdelta[M[p],J] = linear(net)\n",
    "        \n",
    "        # calculate error\n",
    "        err[N] += np.sum((t[M[p],:]-outdelta[M[p],:])**2)\n",
    "        \n",
    "        # update weights\n",
    "        for J in range(nout):               # loop through all output units\n",
    "            for I in range(nindelta):       # loop through all intput units\n",
    "                Wdelta[I,J] += LR*(t[M[p],J]-outdelta[M[p],J])*1.*idelta[M[p],I]\n",
    "                \n",
    "    # print current err if verbose\n",
    "    if verbose:\n",
    "        print(err[N])\n",
    "\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that for testing, I am just presenting linearly-spaced points that span the continuum of training patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "outdelta = np.zeros((testdelta.shape[0],1))\n",
    "for p in range(testdelta.shape[0]):\n",
    "    outdelta[[p],:] = linear(np.matmul(testdelta[[p],:], Wdelta))\n",
    "print('Done testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training data and predictions\n",
    "plt.plot(i,t,'b+',testdelta[:,0],outdelta[:,0])\n",
    "plt.xlabel('input')\n",
    "plt.ylabel('output')\n",
    "plt.title('Neural Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, the network learns a regression line, with slope W and intercept B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get learned network weights and biases\n",
    "print('*** delta rule by hand ***')\n",
    "print('W {} | B {}'.format(Wdelta[0,0], Wdelta[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "### with linear regression in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## basic linear regression\n",
    "##\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(i, t)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "out_regr = regr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training data and predictions\n",
    "plt.plot(i,t,'b+',test,out_regr)\n",
    "plt.xlabel('input')\n",
    "plt.ylabel('output')\n",
    "plt.title('Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('*** using linear regression (scikit-learn) ***')\n",
    "print('slope {} | intercept {}'.format(regr.coef_, regr.intercept_))\n",
    "print('Done with regression!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### here we implement delta rule learning in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## define and train neural network - we will discuss details of these keras pieces later\n",
    "##\n",
    "\n",
    "# import tools for basic keras networks \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "nout = 1\n",
    "# create architecture of simple neural network model\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(nout, \n",
    "                         activation='linear', \n",
    "                         input_shape=(nin,)))\n",
    "\n",
    "# print a model summary\n",
    "print(network.summary())\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print(layer.get_config())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# configure optimizer\n",
    "sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9)\n",
    "\n",
    "# compile network\n",
    "network.compile(optimizer=sgd, \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['accuracy', 'mse'])\n",
    "\n",
    "# now train the network\n",
    "history = network.fit(i, t, verbose=False, epochs=5000)\n",
    "print('Done training!')\n",
    "\n",
    "# model predictions\n",
    "out = network.predict(test)\n",
    "print('Done testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training data and predictions\n",
    "plt.plot(i,t,'b+',test,out)\n",
    "plt.xlabel('input')\n",
    "plt.ylabel('output')\n",
    "plt.title('Neural Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get learned network weights and biases\n",
    "W = network.layers[0].get_weights()[0]     # weights input to hidden\n",
    "B = network.layers[0].get_weights()[1]     # bias to hidden\n",
    "\n",
    "print('*** using Keras ***')\n",
    "print('W {} | B {}'.format(W[0][0], B[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
