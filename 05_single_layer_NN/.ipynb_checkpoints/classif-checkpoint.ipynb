{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Another Simple Linear Network and the Delta Rule\n",
    "##\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as R\n",
    "\n",
    "# supress unnecessary warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create input training patterns and training teacher output\n",
    "\n",
    "Np = # training patterns<br>\n",
    "nin = # input nodes<br>\n",
    "nout = # output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "\n",
    "# +1 -1 +1 -1 -> +1\n",
    "# +1 +1 +1 +1 -> +1\n",
    "# +1 +1 +1 -1 -> -1\n",
    "# +1 -1 -1 +1 -> -1\n",
    "#\n",
    "# one soln: W = [-1 -1 +2 +1], B = 0\n",
    "\n",
    "Np   = 4     # 4 input patterns\n",
    "nin  = 4     # 4 input nodes (will add 5th bias input when doing it by hand)\n",
    "nout = 1     # 1 output node\n",
    "\n",
    "# input patterns (Np x Nin) - note that I am forcing this to have float values\n",
    "i = np.array([[+1., -1., +1., -1.],\n",
    "              [+1., +1., +1., +1.],\n",
    "              [+1., +1., +1., -1.],\n",
    "              [+1., -1., -1., +1.]]);\n",
    "\n",
    "# training outputs\n",
    "t = np.array([[+1.],\n",
    "              [+1.],\n",
    "              [-1.],\n",
    "              [-1.]]);\n",
    "\n",
    "# note that for this example, we are not going to use any test patterns,\n",
    "# we'll just train the network and test it on the training patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we implement delta rule learning by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('********** delta-rule learning by hand **********')\n",
    "\n",
    "# implementing by hand, we want to add the explicit input (with value 1) via the bias weight\n",
    "idelta = np.concatenate((i, np.ones((i.shape[0],1))), axis=1)\n",
    "nindelta = idelta.shape[1]\n",
    "\n",
    "print(idelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "LR = .01\n",
    "\n",
    "# initialize weight matrix to small random values\n",
    "Wdelta = .10*R.rand(nindelta,nout)-.05;\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 5000\n",
    "\n",
    "# tanh activation function exists in numpy\n",
    "# np.tanh()\n",
    "\n",
    "# initialize err array\n",
    "err = np.zeros((epochs))\n",
    "\n",
    "# if verbose, print progress\n",
    "verbose = False\n",
    "\n",
    "# loop through epochs\n",
    "for N in range(epochs):\n",
    "        \n",
    "    # initalize output\n",
    "    outdelta = np.zeros((t.shape[0],1))\n",
    "    \n",
    "    # shuffle order of patterns (M for remapping) - necessary for sgd\n",
    "    M = R.permutation(Np)\n",
    "    \n",
    "    # incremental learning / stochastic gradient descent\n",
    "    for p in range(Np):\n",
    "\n",
    "        # calculate output given input p (using matrix operation in one line of code)\n",
    "        outdelta[[M[p]],:] = np.tanh(np.matmul(idelta[[M[p]],:], Wdelta))\n",
    "        \n",
    "        # now calculate output given input p long-hand (using a for loop instead)\n",
    "        for J in range(nout):\n",
    "            net = 0.\n",
    "            for I in range(nindelta):\n",
    "                net += idelta[M[p],I] * Wdelta[I,J]\n",
    "            outdelta[M[p],J] = np.tanh(net)\n",
    "        \n",
    "        # calculate error\n",
    "        err[N] += np.sum((t[M[p],:]-outdelta[M[p],:])**2)\n",
    "        \n",
    "        # update weights\n",
    "        for J in range(nout):               # loop through all output units\n",
    "            for I in range(nindelta):       # loop through all intput units\n",
    "                Wdelta[I,J] += LR*(t[M[p],J]-outdelta[M[p],J])*(1-outdelta[M[p],J]**2)*idelta[M[p],I]\n",
    "                \n",
    "    # print current err if verbose\n",
    "    if verbose:\n",
    "        print(err[N])\n",
    "        \n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions (testing with the training data here)\n",
    "outdelta = np.zeros((idelta.shape[0],1))\n",
    "for p in range(idelta.shape[0]):\n",
    "    outdelta[[p],:] = np.tanh(np.matmul(idelta[[p],:], Wdelta))\n",
    "print('Done testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** delta rule by hand ***')\n",
    "\n",
    "# print performance\n",
    "for p in range(idelta.shape[0]):\n",
    "    for I in range(idelta.shape[1]-1):                      # print training pattern\n",
    "        print('{0:2.0f} '.format(idelta[p,I]), end='') \n",
    "    for J in range(nout):\n",
    "        print('{0:2.0f} '.format(t[p,J]), end='')           # print true answer\n",
    "    for J in range(nout):\n",
    "        print('{0:6.3f} '.format(outdelta[p,J]))            # print network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** delta rule by hand ***')\n",
    "\n",
    "# get learned network weights and biases\n",
    "print('Weights:')\n",
    "for I in range(idelta.shape[1]-1):\n",
    "    print('from i{0:d} '.format(I+1), end='')\n",
    "    for J in range(nout):\n",
    "        print('{0:7.4f} '.format(Wdelta[I,J]), end='')\n",
    "    print()\n",
    "print('Biases:')\n",
    "for J in range(nout):\n",
    "    print('{0:7.4f} '.format(Wdelta[-1,J]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we implement delta rule learning in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "##\n",
    "## define and train neural network - we will discuss details of these keras pieces later\n",
    "##\n",
    "\n",
    "print()\n",
    "print('********** delta-rule learning using Keras **********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools for basic keras networks \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# create architecture of simple neural network model (using tanh activation function here)\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(nout, \n",
    "                         activation='tanh', \n",
    "                         input_shape=(nin,)))\n",
    "\n",
    "# print a model summary\n",
    "print(network.summary())\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print(layer.get_config())\n",
    "print()\n",
    "\n",
    "# configure optimizer\n",
    "sgd = optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9)\n",
    "\n",
    "# compile network\n",
    "network.compile(optimizer=sgd, \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train the network\n",
    "history = network.fit(i, \n",
    "                      t, \n",
    "                      verbose=False, \n",
    "                      epochs=5000)\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions (remember, testing on the training patterns in this example)\n",
    "out = network.predict(i)\n",
    "print('Done testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** delta rule in Keras ***')\n",
    "\n",
    "# print performance\n",
    "for p in range(i.shape[0]):\n",
    "    for I in range(i.shape[1]):                         # print training pattern\n",
    "        print('{0:2.0f} '.format(i[p,I]), end='') \n",
    "    for J in range(nout):\n",
    "        print('{0:2.0f} '.format(t[p,J]), end='')       # print true answer\n",
    "    for J in range(nout):\n",
    "        print('{0:6.3f} '.format(out[p,J]))             # print network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** delta rule in Keras ***')\n",
    "\n",
    "# get learned network weights and biases\n",
    "W = network.layers[0].get_weights()[0]     # weights input to hidden\n",
    "B = network.layers[0].get_weights()[1]     # bias to hidden\n",
    "\n",
    "# get learned network weights and biases\n",
    "print('Weights:')\n",
    "for I in range(i.shape[1]):\n",
    "    print('from i{0:d} '.format(I+1), end='')\n",
    "    for J in range(nout):\n",
    "        print('{0:7.4f} '.format(W[I,J]), end='')\n",
    "    print()\n",
    "print('Biases:')\n",
    "for J in range(nout):\n",
    "    print('{0:7.4f} '.format(B[J]), end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
