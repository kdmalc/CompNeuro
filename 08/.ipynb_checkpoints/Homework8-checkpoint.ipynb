{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874620ef-c649-4f3c-8d28-3a200414e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941cc3b-0b9f-4bbd-bc0b-f52a994622e6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### read in and prepare Haxby data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c4507e-f2af-43b2-aca6-58ab0740e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Haxby data (see slides on Brightspace for details)\n",
    "\n",
    "def prep_haxby_data(dirpath = ''):\n",
    "    ### load the functional MRI patterns ###\n",
    "\n",
    "    # every 2.5 seconds the scanner records a full brain image\n",
    "    # we have extracted just voxels in ventral temporal lobe\n",
    "    # row number corresponds to image number / time point\n",
    "    # column number corresponds to voxel number within ventral temporal lobe\n",
    "    # there should be 1452 images, and 32450 voxels\n",
    "    full_patterns = np.load(dirpath + 'haxby_vt_patterns.npy')\n",
    "    n_img = full_patterns.shape[0]\n",
    "    n_vox = full_patterns.shape[1]\n",
    "\n",
    "    # if an fMRI experiment takes an hour, you usually wouldn't run \n",
    "    # the scanner for an hour straight\n",
    "    # usually, you would run it for a block of time (several minutes) \n",
    "    # called a 'run'\n",
    "    # each run contains a chunk of the experiment\n",
    "    # if there are several conditions in your experiment, usually you \n",
    "    # try to put each condition within each run\n",
    "    # Haxby et al had 8 experimental conditions, one condition for each \n",
    "    # of the 8 categories they used - they had 12 runs, and within each \n",
    "    # run they presented a block of images from the each category.\n",
    "    n_runs = 12\n",
    "\n",
    "    ### processing the experimental design ###\n",
    "    \n",
    "    # Haxby et al. provide a text file 'labels.txt' which says when \n",
    "    # they presented items from one category or another\n",
    "    # labels.txt has 1453 lines.  \n",
    "    # the first line is header information  \n",
    "    # then there are 1452 lines, one for each image, saying what was \n",
    "    # happening in the experiment at that time point\n",
    "    # each line specifies the category name / condition, and the run \n",
    "    # number (though the header calls this \"chunks\")\n",
    "    # aside from the 8 categories, there is also time when the screen was \n",
    "    # blank, in between category presentations\n",
    "    # they call this 'rest'; we will exclude rest images from our classification\n",
    "\n",
    "    # a bunch of items from the same category would be presented one \n",
    "    # after another\n",
    "    # so if you look at labels.txt, you'll see there will be 9 lines in a \n",
    "    # row that all say 'scissors'\n",
    "\n",
    "    # read the labels.txt file\n",
    "    fid = open(dirpath + 'labels.txt', 'r')\n",
    "    # this command reads in the first line of the file, the header, \n",
    "    # which we don't need \n",
    "    temp = fid.readline()\n",
    "\n",
    "    # these are the 9 different strings that appear in labels.txt\n",
    "    cond_names = ['face', 'house', 'cat', 'shoe', 'scissors', 'bottle', \n",
    "                  'scrambledpix', 'chair', 'rest']\n",
    "    # this will store the 'one-hot' target values for the classifier\n",
    "    all_targets = np.zeros([n_img, len(cond_names)])\n",
    "    # this will store the run index\n",
    "    all_runs = np.zeros([n_img,])\n",
    "\n",
    "    # now we iterate through the 1452 lines in labels.txt\n",
    "    # line.split breaks the string into 2 parts\n",
    "    # the first is 'this_cond' which says which category/condition (or rest)\n",
    "    # the second is 'this_run' which tells you the functional run of this image \n",
    "    imgcount = 0\n",
    "    for line in fid:\n",
    "        temp = line.split()\n",
    "        this_cond = temp[0]\n",
    "        this_run = temp[1]\n",
    "        all_targets[imgcount, cond_names.index(this_cond)] = 1\n",
    "        all_runs[imgcount] = int(this_run)\n",
    "        imgcount += 1\n",
    "\n",
    "    ### cheap version of accounting for the hemodynamic lag ###\n",
    "\n",
    "    # as we reviewed in lecture, there is a lag from when a stimulus is \n",
    "    # presented, to when the brain's vasculature has its peak response\n",
    "    # one can properly take this hemodynamic lag into account, but we \n",
    "    # are going to do a short-cut\n",
    "    # if each image takes 2.5 seconds to acquire, and it takes about 5 \n",
    "    # seconds for the brain to reach its peak response, we can shift the \n",
    "    # condition labels forward by two images\n",
    "    # an easy way to do this is to concatenate 2 rows of zeros at the \n",
    "    # beginning of the targets matrix and then remove 2 rows of zeros \n",
    "    # from the end of the targets matrix\n",
    "    # that pushes every label forward by 5 seconds\n",
    "    \n",
    "    # just shift all the regressors over by 2 time points\n",
    "    # each image takes 2.5 seconds to acquire\n",
    "    prepend_zeros = np.zeros([2, all_targets.shape[1]])\n",
    "    shift_all_targets = np.concatenate((prepend_zeros, all_targets))\n",
    "    mask = np.ones(shift_all_targets.shape[0], dtype=bool)\n",
    "    mask[shift_all_targets.shape[0]-2:shift_all_targets.shape[0]] = False\n",
    "    shift_all_targets = shift_all_targets[mask, :]\n",
    "    \n",
    "    # now that we are done just replace the original target labels \n",
    "    # with the shifted ones\n",
    "    all_targets = shift_all_targets\n",
    "\n",
    "    ### remove rests from runs ###\n",
    "    \n",
    "    # modify the labels matrix\n",
    "    # remove the rest unit, we don't want to classify rest patterns\n",
    "    temp_targets = all_targets[:, :8].copy()\n",
    "    # get rid of images where there isn't a category being presented\n",
    "    # and make it a boolean array\n",
    "    label_present = np.sum(temp_targets, axis=1)> 0\n",
    "\n",
    "    # label_present is a boolean array indicating when a category is \n",
    "    # being presented\n",
    "    # we are using it as a mask to get rid of all the time-points \n",
    "    # where nothing is being presented\n",
    "    # in other words it gets rid of all the rest periods\n",
    "    targets = temp_targets[label_present, :]\n",
    "    patterns = full_patterns[label_present, :]\n",
    "    runs = all_runs[label_present]\n",
    "    \n",
    "    ### z-scoring is a kind of normalization ###\n",
    "    n_vox = patterns.shape[1]\n",
    "    for i in range(n_vox):\n",
    "        patterns[:,i] = (patterns[:,i] - patterns[:,i].mean()) / patterns[:,i].std()\n",
    "\n",
    "    # for a set of numbers, get the mean and standard deviation\n",
    "    # subtract the mean off every number, divide every number \n",
    "    # by the standard deviation\n",
    "    # here we normalize our patterns using a temporal z-score,\n",
    "    # meaning that we normalize the values for each voxel, across time    \n",
    "    \n",
    "    # here are the arrays you need to do classification\n",
    "    return patterns, targets, runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5a472-286d-4c22-b1f4-04d7b48bab5b",
   "metadata": {},
   "source": [
    "patterns.shape, targets.shape, runs.shape<br>\n",
    "864 : number of fMRI brain scans (onebrain scan per object image)<br>\n",
    "32450 : number voxels in IT cortex (using an anatomical mask)<br>\n",
    "8 : number of object categories (face, house, cat, shoe, scissors, bottle, scrambled, chair, rest)\n",
    "\n",
    "patterns: contains voxel (fMRI) data\n",
    "\n",
    "targets: contains the condition (category) associated with each fMRI scan\n",
    "\n",
    "runs: which \"run\" each scan is associated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60283587-270d-4431-8159-ce5e6d64935e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864, 32450)\n",
      "(864, 8)\n",
      "(864,)\n"
     ]
    }
   ],
   "source": [
    "# load Haxby et al. data (see slides on Brightspace)\n",
    "\n",
    "patterns, targets, runs = prep_haxby_data()\n",
    "\n",
    "print(patterns.shape)\n",
    "print(targets.shape)\n",
    "print(runs.shape)\n",
    "\n",
    "cond_names = ['face', 'house', 'cat', 'shoe', 'scissors', 'bottle',\n",
    "              'scrambledpix', 'chair', 'rest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92eb16-6b40-4254-8a8b-e23c991d3e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45a8be1-ab6a-4a66-b781-7a0f6f86fabe",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### \"feature selection\"\n",
    "\n",
    "with \"feature selection\", selecting voxels that modulate statistically significantly according to object category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec0f3e5-8b6f-4605-b387-1c1509d0838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"feature selection\" based on picking statistically significant voxels\n",
    "\n",
    "def feature_selection(train_pats, train_targs, test_pats):\n",
    "    pval = 0.1\n",
    "    \n",
    "    keep_these = np.zeros((train_pats.shape[1],))\n",
    "    \n",
    "    # loop through every voxel\n",
    "    for v in range(train_pats.shape[1]):\n",
    "        groups = []\n",
    "        for c in range(train_targets.shape[1]):\n",
    "            groups.append(train_pats[train_targs[:, c] == 1., v])\n",
    "           \n",
    "        # and statistically analyze it for category modulation\n",
    "        temp = sps.f_oneway(groups[0], groups[1], groups[2], groups[3],\n",
    "                            groups[4], groups[5], groups[6], groups[7])\n",
    "\n",
    "        if temp.pvalue < pval:\n",
    "            keep_these[v] = 1.\n",
    "    \n",
    "    keep_these = keep_these.astype(bool)\n",
    "    train_pats = train_pats[:, keep_these]\n",
    "    test_pats = test_pats[:, keep_these]\n",
    "    \n",
    "    return train_pats, test_pats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95313beb-f17b-43d9-8756-77aa874a4d9c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### some starting points for Q1 \n",
    "\n",
    "(see slides on Brightspace from class for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80fc8f82-85fd-42e3-9236-093d1a205a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example \"leaving out\" a particular run\n",
    "\n",
    "example_test_run = 1\n",
    "\n",
    "train_these = runs != example_test_run\n",
    "test_these  = runs == example_test_run\n",
    "\n",
    "# an example of logical indexing\n",
    "train_patterns = patterns[train_these, :]\n",
    "train_targets = targets[train_these, :]\n",
    "\n",
    "test_patterns = patterns[test_these, :]\n",
    "test_targets = targets[test_these, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f78a9fa6-7ddc-441a-9612-e48fbd9bc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"feature selection\" of statistically category-modulated voxels\n",
    "\n",
    "fs_train_patterns, fs_test_patterns = feature_selection(train_patterns,\n",
    "                                                        train_targets,\n",
    "                                                        test_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad2dadaf-48dd-42fa-a3cd-c4371aa4bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 12568)\n",
      "(792, 8)\n",
      "(72, 12568)\n",
      "(72, 8)\n"
     ]
    }
   ],
   "source": [
    "print(fs_train_patterns.shape)\n",
    "print(train_targets.shape)\n",
    "print(fs_test_patterns.shape)\n",
    "print(test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a2fce4a-41af-4385-a528-9cec3726cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12568\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# report some metrics on Haxby experiment (n_vox is for this fold)\n",
    "\n",
    "n_runs = np.max(runs).astype('int') + 1\n",
    "n_vox  = fs_train_patterns.shape[1]\n",
    "n_cats = targets.shape[1]\n",
    "\n",
    "cond_names = ['face', 'house', 'cat', 'shoe', 'scissors', 'bottle', \n",
    "              'scrambledpix', 'chair', 'rest']\n",
    "\n",
    "print(n_runs)\n",
    "print(n_vox)\n",
    "print(n_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ebb25-aba2-4f35-80d1-14c798040673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4977678a-e405-4651-ba68-db4770a1be8b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### function to scramble targets for permutation test\n",
    "\n",
    "(as described in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ea2870-1fbd-49d1-9d71-e02e85d728fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to scramble the category labels for a permutation analysis\n",
    "\n",
    "def scramble_targets(targets, runs):\n",
    "    # there are 12 runs\n",
    "    n_runs = np.max(runs).astype('int') + 1\n",
    "    \n",
    "    # there are 8 categories\n",
    "    n_cats = targets.shape[1]\n",
    "    \n",
    "    # this will contain the scrambled category labels\n",
    "    scram_targets = np.zeros(targets.shape)\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        # first find the category labels just for this run\n",
    "        these_targets = targets[runs==i, :].copy()\n",
    "        \n",
    "        # this shuffles the columns of these_targets, which preserves \n",
    "        # the block structure of the experiment\n",
    "        scram_targets_this_run = these_targets[:, np.random.permutation(n_cats)]\n",
    "        \n",
    "        # this copies the scrambled targets for this run into the \n",
    "        # appropriate rows of the scrambled category labels matrix\n",
    "        scram_targets[runs==i,:] = scram_targets_this_run\n",
    "\n",
    "    return scram_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b1acaef-7266-4dc2-817b-bbe6bffe8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scram_targets = scramble_targets(targets, runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a16cb75a-14de-45c7-b096-c19d40302656",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_test_run = 3\n",
    "\n",
    "train_these = runs != example_test_run\n",
    "test_these  = runs == example_test_run\n",
    "\n",
    "# an example of logical indexing\n",
    "train_patterns = patterns[train_these, :]\n",
    "scram_train_targets = scram_targets[train_these, :]\n",
    "\n",
    "test_patterns = patterns[test_these, :]\n",
    "test_targets = targets[test_these, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2921feb4-d710-4be0-ba19-30caf903b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_train_patterns, fs_test_patterns = feature_selection(train_patterns,\n",
    "                                                        scram_train_targets,\n",
    "                                                        test_patterns)\n",
    "\n",
    "n_vox  = fs_train_patterns.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4a6a1-bb8c-4fa1-8779-6f65c09f5a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
