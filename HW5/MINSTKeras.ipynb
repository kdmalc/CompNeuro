{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# supress unnecessary warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##\n",
    "## MINST happens to be preloaded with Keras\n",
    "##\n",
    "\n",
    "# load mnist\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# display some digits\n",
    "fig = plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(train_images[i], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Digit: {}\".format(train_labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "# image shape\n",
    "sz = train_images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Original Training and Testing Patterns ***\n",
      "Training images shape:  (60000, 28, 28)\n",
      "Training images type:   <class 'numpy.uint8'>\n",
      "Testing images shape:   (10000, 28, 28)\n",
      "Testing images type:    <class 'numpy.uint8'>\n",
      "\n",
      "*** Reformatted Training and Testing Patterns ***\n",
      "Training images shape:  (60000, 784)\n",
      "Training images type:   <class 'numpy.float32'>\n",
      "Testing images shape:   (10000, 784)\n",
      "Testing images type:    <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## preprocess training and testing patterns\n",
    "##\n",
    "## this is a common first step for training any neural network\n",
    "##\n",
    "\n",
    "# check out dimensions and types of mnist data\n",
    "print('*** Original Training and Testing Patterns ***')\n",
    "print('Training images shape: ', train_images.shape)\n",
    "print('Training images type:  ', type(train_images[0][0][0]))\n",
    "print('Testing images shape:  ', test_images.shape)\n",
    "print('Testing images type:   ', type(test_images[0][0][0]))\n",
    "print()\n",
    "\n",
    "# need to reshape and preprocess the training/testing images\n",
    "train_images_vec = train_images.reshape((train_images.shape[0], train_images.shape[1] * train_images.shape[2]))\n",
    "train_images_vec = train_images_vec.astype('float32') / 255\n",
    "test_images_vec = test_images.reshape((test_images.shape[0], test_images.shape[1] * test_images.shape[2]))\n",
    "test_images_vec = test_images_vec.astype('float32') / 255\n",
    "\n",
    "# display new input dimensions/type\n",
    "print('*** Reformatted Training and Testing Patterns ***')\n",
    "print('Training images shape: ', train_images_vec.shape)\n",
    "print('Training images type:  ', type(train_images_vec[0][0]))\n",
    "print('Testing images shape:  ', test_images_vec.shape)\n",
    "print('Testing images type:   ', type(test_images_vec[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 training labels as labels:\n",
      " [5 0 4 1 9]\n",
      "First 5 training labels as one-hot encoded vectors:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## MINST labels are numeric - want to reformat as one-hot coded vectors\n",
    "##\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# also need to categorically encode the labels\n",
    "print('First 5 training labels as labels:\\n', train_labels[:5])\n",
    "\n",
    "train_labels_onehot = to_categorical(train_labels)\n",
    "test_labels_onehot = to_categorical(test_labels)\n",
    "print('First 5 training labels as one-hot encoded vectors:\\n', train_labels_onehot[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start with a simple one-layer neural network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kdmen\\miniconda3\\envs\\NSCenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################\n",
    "##\n",
    "## define and train neural network in Keras\n",
    "##\n",
    "\n",
    "# import tools for basic keras networks \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers# number of input node (nin = 784)\n",
    "nin = train_images_vec.shape[1]\n",
    "\n",
    "# number of output nodes (nout = 10)\n",
    "nout = train_labels_onehot.shape[1]\n",
    "\n",
    "# create architecture of simple neural network model\n",
    "# input layer  : 28*28 = 784 (nin) input nodes\n",
    "# output layer : 10 (nout) sigmoid output nodes\n",
    "\n",
    "# Sequential is a basic stack of layers (most basic type of neural network)\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "#\n",
    "# this initializes a blank Sequential network\n",
    "network = models.Sequential()\n",
    "\n",
    "# network.add() adds the first (and only) layer to the network (the output layer)\n",
    "# \n",
    "# layers.Dense() is a densely connect layer\n",
    "# with nout units\n",
    "# with a sigmoidal activation function\n",
    "# that receives input from an input later with a specific shape\n",
    "# \n",
    "network.add(layers.Dense(nout, \n",
    "                         activation='sigmoid', \n",
    "                         input_shape=(nin,)))\n",
    "\n",
    "# with multi-layer networks, we will have additional network.add() calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print a model summary\n",
    "print(network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Basic Network Structure ***\n",
      "layer name : dense | input shape : (?, 784) | output shape : (?, 10)\n",
      "\n",
      "*** Detailed Network Layer Information ***\n",
      "{'name': 'dense', 'trainable': True, 'batch_input_shape': (None, 784), 'dtype': 'float32', 'units': 10, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None, 'dtype': 'float32'}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print more info about the network\n",
    "\n",
    "print('*** Basic Network Structure ***')\n",
    "for layer in network.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print()\n",
    "print('*** Detailed Network Layer Information ***')\n",
    "for layer in network.layers:\n",
    "    print(layer.get_config())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile network\n",
    "#\n",
    "# configures the network for training, specifying optimizer and loss function\n",
    "#\n",
    "# optimizer='sgd'           : stochastic gradient descent (simplest, not the smartest)\n",
    "# loss='mean_squared_error' : uses MSE (MSE = 1/N * SSE)\n",
    "# metrics=['accuracy']      : what is printed when verbose=True\n",
    "network.compile(optimizer='sgd', \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['accuracy', 'mse'])\n",
    "\n",
    "# if leave off metrics, only saves loss and val_loss\n",
    "# network.compile(optimizer='sgd', \n",
    "#                 loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape : (784, 10)\n",
      "weight (W) initial values:\n",
      "[[ 0.0434696  -0.07312791  0.06791828 ...  0.02409373  0.01383343\n",
      "  -0.01871774]\n",
      " [ 0.04646685  0.05897155  0.03518604 ...  0.02873019  0.08681963\n",
      "  -0.08540788]\n",
      " [-0.02982108  0.01450865  0.00567929 ...  0.04022194  0.01765777\n",
      "  -0.02914935]\n",
      " ...\n",
      " [-0.07688302 -0.08675285  0.04836226 ...  0.03645513 -0.07965605\n",
      "   0.00210171]\n",
      " [-0.05746371  0.00268188  0.00495815 ... -0.02069464 -0.03127427\n",
      "   0.08069774]\n",
      " [-0.0851071  -0.00478388 -0.00013306 ...  0.0681871  -0.01552822\n",
      "  -0.01991042]]\n"
     ]
    }
   ],
   "source": [
    "# note that before training, weights are initialized to small random values\n",
    "print('W shape : {}'.format(network.layers[0].get_weights()[0].shape))\n",
    "print('weight (W) initial values:')\n",
    "print(network.layers[0].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1454 - acc: 0.1524 - mean_squared_error: 0.1454 - val_loss: 0.1056 - val_acc: 0.2392 - val_mean_squared_error: 0.1056\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0978 - acc: 0.2861 - mean_squared_error: 0.0978 - val_loss: 0.0917 - val_acc: 0.3507 - val_mean_squared_error: 0.0917\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0894 - acc: 0.3834 - mean_squared_error: 0.0894 - val_loss: 0.0862 - val_acc: 0.4305 - val_mean_squared_error: 0.0862\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0851 - acc: 0.4449 - mean_squared_error: 0.0851 - val_loss: 0.0824 - val_acc: 0.4782 - val_mean_squared_error: 0.0824\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0818 - acc: 0.4816 - mean_squared_error: 0.0818 - val_loss: 0.0793 - val_acc: 0.5122 - val_mean_squared_error: 0.0793\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0789 - acc: 0.5080 - mean_squared_error: 0.0789 - val_loss: 0.0765 - val_acc: 0.5388 - val_mean_squared_error: 0.0765\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0764 - acc: 0.5322 - mean_squared_error: 0.0764 - val_loss: 0.0739 - val_acc: 0.5618 - val_mean_squared_error: 0.0739\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0740 - acc: 0.5537 - mean_squared_error: 0.0740 - val_loss: 0.0716 - val_acc: 0.5818 - val_mean_squared_error: 0.0716\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0719 - acc: 0.5734 - mean_squared_error: 0.0719 - val_loss: 0.0694 - val_acc: 0.6075 - val_mean_squared_error: 0.0694\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0699 - acc: 0.5926 - mean_squared_error: 0.0699 - val_loss: 0.0674 - val_acc: 0.6287 - val_mean_squared_error: 0.0674\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0680 - acc: 0.6102 - mean_squared_error: 0.0680 - val_loss: 0.0655 - val_acc: 0.6478 - val_mean_squared_error: 0.0655\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0663 - acc: 0.6251 - mean_squared_error: 0.0663 - val_loss: 0.0637 - val_acc: 0.6650 - val_mean_squared_error: 0.0637\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0647 - acc: 0.6406 - mean_squared_error: 0.0647 - val_loss: 0.0621 - val_acc: 0.6800 - val_mean_squared_error: 0.0621\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0633 - acc: 0.6528 - mean_squared_error: 0.0633 - val_loss: 0.0606 - val_acc: 0.6892 - val_mean_squared_error: 0.0606\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0619 - acc: 0.6634 - mean_squared_error: 0.0619 - val_loss: 0.0591 - val_acc: 0.6980 - val_mean_squared_error: 0.0591\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0606 - acc: 0.6725 - mean_squared_error: 0.0606 - val_loss: 0.0578 - val_acc: 0.7070 - val_mean_squared_error: 0.0578\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 0.0594 - acc: 0.6814 - mean_squared_error: 0.0594 - val_loss: 0.0566 - val_acc: 0.7178 - val_mean_squared_error: 0.0566\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0583 - acc: 0.6900 - mean_squared_error: 0.0583 - val_loss: 0.0554 - val_acc: 0.7282 - val_mean_squared_error: 0.0554\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0573 - acc: 0.6974 - mean_squared_error: 0.0573 - val_loss: 0.0544 - val_acc: 0.7352 - val_mean_squared_error: 0.0544\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0563 - acc: 0.7050 - mean_squared_error: 0.0563 - val_loss: 0.0534 - val_acc: 0.7432 - val_mean_squared_error: 0.0534\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "# now train the network\n",
    "#\n",
    "# training requires training patterns (train_image_vec) and teachers (train_labels_onehot)\n",
    "#\n",
    "# sets # training epochs, validation (described later), and batch_size\n",
    "#\n",
    "# set verbose=True to see training unfold\n",
    "history = network.fit(train_images_vec, \n",
    "                      train_labels_onehot, \n",
    "                      verbose=True, \n",
    "                      validation_split=.1, \n",
    "                      epochs=20, \n",
    "                      batch_size=128)\n",
    "print('Done training!')\n",
    "\n",
    "# if run this again, it will do more training on the same network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.14539550761602543, 0.09775129275189506, 0.08939633740760662, 0.08505553519946557, 0.08177220672369004, 0.07892380485269758, 0.07635598980938947, 0.07401582277924926, 0.07186889665656619, 0.06988676391045252, 0.06804851598651321, 0.0663395666413837, 0.06474892563069308, 0.06326795901965213, 0.061889965460256297, 0.06060863778105489, 0.05941713814602958, 0.0583081466599747, 0.05727381309535768, 0.05630702666883115], 'acc': [0.15240741, 0.28607407, 0.3834074, 0.44494444, 0.4815741, 0.5079815, 0.5322037, 0.55366665, 0.5733704, 0.5925926, 0.61016667, 0.6251111, 0.6405926, 0.65275925, 0.6633889, 0.6724815, 0.6814259, 0.689963, 0.6973889, 0.7050185], 'mean_squared_error': [0.14539546, 0.09775129, 0.089396305, 0.08505558, 0.08177222, 0.078923844, 0.076356, 0.07401583, 0.07186888, 0.069886744, 0.06804853, 0.06633957, 0.06474891, 0.063267976, 0.061889958, 0.06060865, 0.05941714, 0.058308147, 0.057273827, 0.056307055], 'val_loss': [0.10562044195334117, 0.09172966508070628, 0.08618166426817576, 0.08242852940162022, 0.07928968385855358, 0.07647765356302261, 0.0739164558450381, 0.07156485092639923, 0.06939022038380305, 0.06736832455794016, 0.06548355382680893, 0.06372374621033669, 0.06208269799749056, 0.0605537660419941, 0.05913340613245964, 0.057813290417194366, 0.05658787954847018, 0.055447371393442156, 0.05438319898645083, 0.05338874148329099], 'val_acc': [0.23916666, 0.35066667, 0.4305, 0.47816667, 0.5121667, 0.5388333, 0.5618333, 0.58183336, 0.6075, 0.62866664, 0.64783335, 0.665, 0.68, 0.68916667, 0.698, 0.707, 0.71783334, 0.72816664, 0.73516667, 0.7431667], 'val_mean_squared_error': [0.105620444, 0.09172966, 0.08618166, 0.08242854, 0.079289675, 0.076477654, 0.07391645, 0.07156485, 0.069390215, 0.06736833, 0.065483555, 0.06372376, 0.062082686, 0.060553767, 0.059133407, 0.057813294, 0.056587875, 0.055447377, 0.0543832, 0.053388737]}\n"
     ]
    }
   ],
   "source": [
    "# history contains the loss (training loss), accuracy, mse, val_loss (validation loss), \n",
    "# val_accuracy (validation accuracy), val_mse, as a Python dictionary\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5672/4105741310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# access one of the elements of the dictionary by name (in this case training accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "# access one of the elements of the dictionary by name (in this case training accuracy)\n",
    "print(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call network.evaluate() if you have test patterns and test answers and want to know performance\n",
    "test_loss, test_acc = network.evaluate(test_images_vec, \n",
    "                                       test_labels_onehot, \n",
    "                                       verbose=False)\n",
    "\n",
    "print('test_loss (MSE)     : {}'.format(test_loss))\n",
    "print('test_acc (%Correct) : {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call network.predict() if you have test patterns and want to get predicted outputs\n",
    "out = network.predict(test_images_vec)\n",
    "\n",
    "print('dimensions of out : {}'.format(out.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-layer neural network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# number of input node (nin = 784)\n",
    "nin = train_images_vec.shape[1]\n",
    "\n",
    "# create a multi-layer network with two layers of nhid hidden nodes\n",
    "nhid = 100\n",
    "\n",
    "# number of output nodes (nout = 10)\n",
    "nout = train_labels_onehot.shape[1]\n",
    "\n",
    "# create architecture of multi-layer neural network model\n",
    "# input layer  : 28*28 = 784 (nin) input nodes\n",
    "# hidden layer : 100 hidden nodes\n",
    "# output layer : 10 (nout) softmax output nodes\n",
    "\n",
    "# this initializes a blank Sequential network\n",
    "network2 = models.Sequential()\n",
    "\n",
    "# add layers to the initialized network\n",
    "# \n",
    "# hidden layer (input->hidden) - using relu because of its nice mathematical properties\n",
    "network2.add(layers.Dense(nhid, \n",
    "                          kernel_regularizer=regularizers.l2(0.01), \n",
    "                          activation='relu', \n",
    "                          input_shape=(nin,)))\n",
    "\n",
    "# hidden layer (hidden->hidden) - using relu because of its nice mathematical properties\n",
    "network2.add(layers.Dense(nhid, \n",
    "                          kernel_regularizer=regularizers.l2(0.01), \n",
    "                          activation='relu'))\n",
    "\n",
    "# output layer (hidden->output) - using softmax as per discussion in class\n",
    "network2.add(layers.Dense(nout, \n",
    "                          kernel_regularizer=regularizers.l2(0.01), \n",
    "                          activation='softmax'))\n",
    "\n",
    "# regularizers (L1 or L2) can potentially help with over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a model summary\n",
    "print(network2.summary())\n",
    "\n",
    "# print more info about the network\n",
    "\n",
    "print('*** Basic Network Structure ***')\n",
    "for layer in network2.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print()\n",
    "print('*** Detailed Network Layer Information ***')\n",
    "for layer in network2.layers:\n",
    "    print(layer.get_config())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile network\n",
    "#\n",
    "# using 'adam' optimizer (extension of stochastic gradient descent)\n",
    "#\n",
    "# using categorical cross entropy with softmax output activation\n",
    "network2.compile(optimizer='adam', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train the network\n",
    "#\n",
    "# validation is used to adjust optimization\n",
    "history = network2.fit(train_images_vec, \n",
    "                       train_labels_onehot, \n",
    "                       verbose=True, \n",
    "                       validation_split=.1, \n",
    "                       epochs=20, \n",
    "                       batch_size=128)\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
