{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Homework 3\n",
    "##\n",
    "## simple MNIST classifier network\n",
    "##\n",
    "## NSC3270/5270 Spring 2019\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# supress some unnecessary warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load, display, and format mnist images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# load mnist images\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions and type of images and labels\n",
    "\n",
    "print('train')\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(type(train_images))\n",
    "print(type(train_labels))\n",
    "print()\n",
    "\n",
    "print('test')\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "print(type(test_images))\n",
    "print(type(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60,000 train images and 10,000 test images. Each image is 28x28 pixels (gray scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 9 digits\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(train_images[i], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Digit: {}\".format(train_labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reformat training and testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out (again) dimensions and types of mnist data\n",
    "print('Training images shape: ', train_images.shape)\n",
    "print('Training pixel type:   ', type(train_images[0][0][0]))\n",
    "print('Testing images shape:  ', test_images.shape)\n",
    "print('Testing pixel type:    ', type(test_images[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images\n",
    "Ntr = train_images.shape[0]\n",
    "Nts = test_images.shape[0]\n",
    "\n",
    "# image shape\n",
    "szx = train_images.shape[1]\n",
    "szy = train_images.shape[2]\n",
    "\n",
    "# need to reshape the 28x28 training/testing images as vectors\n",
    "train_images_vec = train_images.reshape((Ntr, szx * szy))\n",
    "test_images_vec = test_images.reshape(  (Nts, szx * szy))\n",
    "\n",
    "# deciding to normalize the pixels to 0..1 and recase as float32\n",
    "train_images_vec = train_images_vec.astype('float32') / 255\n",
    "test_images_vec = test_images_vec.astype('float32') / 255\n",
    "\n",
    "# display new input dimensions/type\n",
    "print('New training images shape: ', train_images_vec.shape)\n",
    "print('New training pixel type:   ', type(train_images_vec[0][0]))\n",
    "print('New testing images shape:  ', test_images_vec.shape)\n",
    "print('New testing pixel type:    ', type(test_images_vec[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reformat training and testing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out dimensions and types of mnist data\n",
    "print('Training labels shape: ', train_labels.shape)\n",
    "print('Training labels type:  ', type(train_labels[0]))\n",
    "print()\n",
    "\n",
    "# check out what the first 9 labels look like\n",
    "print(\"First 9 training labels as labels:\\n\", train_labels[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# also need to categorically encode the labels as \"one hot\"\n",
    "\n",
    "train_labels_onehot = to_categorical(train_labels)\n",
    "test_labels_onehot = to_categorical(test_labels)\n",
    "\n",
    "print(\"First 9 training labels as one-hot encoded vectors:\\n\", train_labels_onehot[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display new output dimensions/type\n",
    "print('New training labels shape (one hot): ', train_labels_onehot.shape)\n",
    "print('New training labels type (one hot):  ', type(train_labels_onehot[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define and train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools for basic keras networks \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "nout = 10\n",
    "\n",
    "# create architecture of simple neural network model\n",
    "# input layer  : 28*28 = 784 input nodes\n",
    "# output layer : 10 (nout) output nodes\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(nout, \n",
    "                         activation='sigmoid', \n",
    "                         input_shape=(szx * szy,)))\n",
    "\n",
    "# print a model summary\n",
    "print(network.summary())\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print(layer.get_config())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile network\n",
    "network.compile(optimizer='sgd', \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# now train the network\n",
    "history = network.fit(train_images_vec, \n",
    "                      train_labels_onehot, \n",
    "                      verbose=True, \n",
    "                      validation_split=.1, \n",
    "                      epochs=20, \n",
    "                      batch_size=128)\n",
    "print('Done training!')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test network\n",
    "test_loss, test_acc = network.evaluate(test_images_vec, \n",
    "                                       test_labels_onehot, \n",
    "                                       verbose=True)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some pieces needed to complete Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get learned network weights and biases\n",
    "\n",
    "W = network.layers[0].get_weights()[0]     # weights input to hidden\n",
    "B = network.layers[0].get_weights()[1]     # bias to hidden\n",
    "\n",
    "print('W {} | B {}'.format(W.shape, B.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions (all 10000 test images)\n",
    "out = network.predict(test_images_vec)\n",
    "\n",
    "# model predictions (a single test image)\n",
    "example = test_images_vec[123]\n",
    "print(example.shape)\n",
    "\n",
    "# vector passed to network.predict must be (?, 784)\n",
    "example = example.reshape((1,example.shape[0]))\n",
    "print(example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "##\n",
    "## Homework 3 Solution Area\n",
    "##\n",
    "\n",
    "## Q1. The original MNIST test_labels numpy array contains the digit value associated\n",
    "## with the corresponding digit image (test_images). The output from the network (from\n",
    "## out = network.predict(test_images_vec) above) contains the activations of the 10\n",
    "## output nodes for every test image presented to the network. Write a function that\n",
    "## takes the (10000,10) numpy array of output (of type float) activations and returns a \n",
    "## (10000,) numpy array of discrete digit classification by the network (of type int).\n",
    "## Specifically, create a test_decisions numpy array of the same size and type as the\n",
    "## MNIST test_labels array you started with. Whereas test_labels shows the correct\n",
    "## answer, test_decisions shows the ultimate decision by the network. Below you will use \n",
    "## both arrays to pull out test images that the network classifies correctly vs. incorrectly.\n",
    "##\n",
    "## To turn a numpy array of continuous output activations into a discrete digit classification,\n",
    "## just take the maximum output as the \"winner\" that \"takes all\", determining the classification.\n",
    "##\n",
    "## In your function, feel free to use for loops. Here, we are looking to see that you understand\n",
    "## how to use the outputs generated by the network, not whether you can program using the\n",
    "## most efficient Python style.\n",
    "\n",
    "### INSERT Q1 SOLUTION HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Q2. Comparing the correct answers (test_labels) and network classifications (test_decisions),\n",
    "## for each digit 0..9, find one test image (test_image) that is classified by the network\n",
    "## correctly and one test image that is classified by the network incorrectly. \n",
    "##\n",
    "## Create a 2x10 plot of digit images (feel free to adapt the code above that uses subplot), with a \n",
    "## column for each digit 0..9 with the first row showing examples correctly classified (one example \n",
    "## for each digit) and the second row showing the examples incorrectly classified (one example \n",
    "## for each digit). Each subplot title should show the answer and the classification response \n",
    "## (e.g., displaying 4/2 as the title, if the correct answer is 4 and the classification was 2).\n",
    "##\n",
    "\n",
    "### INSERT Q2 SOLUTION HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Q3. Create \"images\" of the connection weight adapting the code used to display\n",
    "## the actual digit images. There should be 10 weight images, an image for each\n",
    "## set of weight connecting the input layer (784 inputs) to each output node.\n",
    "## You will want to reshape the (784,1) vector of weights to a (28,28) image and\n",
    "## display the result using imshow()\n",
    "\n",
    "### INSERT Q3 SOLUTION HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Q4. Use the weight matrix (W), bias vector (B), and activation function (simple sigmoid)\n",
    "## to reproduce in your own code the outputs (out) generated by the network (from\n",
    "## this out = network.predict(test_images_vec))\n",
    "##\n",
    "## The simple sigmoid activation function is defined as follows:\n",
    "## f(x) = 1 / (1+exp(-x))\n",
    "##\n",
    "## Confirm that your output vectors and the keras-produced output vectors are the same\n",
    "## (within some small epsilon since floating point calculations will often not come out\n",
    "## exactly the same on computers).\n",
    "##\n",
    "\n",
    "### INSERT Q4 SOLUTION HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
